{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.gpuarray): pygpu was configured but could not be imported or is too old (version 0.6 or higher required)\n",
      "NoneType: None\n",
      "/home/airsplay/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import argparse\n",
    "import chainer\n",
    "import pickle\n",
    "import importlib\n",
    "from collections import namedtuple, defaultdict\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "from qanta import logging\n",
    "from qanta.config import conf\n",
    "from qanta.guesser.abstract import AbstractGuesser\n",
    "from qanta.util.multiprocess import _multiprocess\n",
    "from qanta.buzzer import configs\n",
    "from qanta.buzzer.progress import ProgressBar\n",
    "from qanta.buzzer.trainer import Trainer\n",
    "from qanta.buzzer.iterator import QuestionIterator\n",
    "from qanta.buzzer.util import load_quizbowl, GUESSERS\n",
    "from qanta.buzzer.models import MLP, RNN\n",
    "from qanta.buzzer import constants as bc\n",
    "from qanta.util import constants as c\n",
    "from qanta import logging\n",
    "\n",
    "log = logging.get(__name__)\n",
    "N_GUESSERS = len(GUESSERS)\n",
    "Batch = namedtuple('Batch', ['qids', 'answers', 'mask', 'vecs', 'results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-25 17:45:31,379 - qanta.buzzer.util - INFO - Merging guesser DataFrames.\n",
      "2017-05-25 17:45:31,380 - qanta.buzzer.util - INFO - Merged buzzertrain exists, skipping.\n",
      "2017-05-25 17:45:31,381 - qanta.buzzer.util - INFO - Merged buzzerdev exists, skipping.\n",
      "2017-05-25 17:45:31,382 - qanta.buzzer.util - INFO - Merged dev exists, skipping.\n",
      "2017-05-25 17:45:31,383 - qanta.buzzer.util - INFO - Merged test exists, skipping.\n",
      "2017-05-25 17:45:31,384 - qanta.buzzer.util - INFO - Merged expo exists, skipping.\n",
      "2017-05-25 17:45:31,385 - qanta.buzzer.util - INFO - Loading data\n",
      "2017-05-25 17:45:31,387 - qanta.datasets.quiz_bowl - WARNING - Using QuizBowlDataset with guesser and buzzer training data, make sure you know what you are doing!\n",
      "2017-05-25 17:45:41,061 - qanta.buzzer.util - INFO - Number of options 8247\n",
      "2017-05-25 17:46:19,307 - qanta.buzzer.util - INFO - Loading buzzertrain guesses\n",
      "2017-05-25 17:46:26,957 - qanta.buzzer.util - INFO - Loading buzzerdev guesses\n",
      "2017-05-25 17:46:28,476 - qanta.buzzer.util - INFO - Loading dev guesses\n",
      "2017-05-25 17:46:34,721 - qanta.buzzer.util - INFO - Loading test guesses\n",
      "2017-05-25 17:46:34,747 - qanta.buzzer.util - INFO - Loading expo guesses\n"
     ]
    }
   ],
   "source": [
    "option2id, all_guesses = load_quizbowl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't rerun above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# without positional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict, namedtuple\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from qanta.config import conf\n",
    "from qanta.buzzer.util import GUESSERS\n",
    "from qanta.buzzer import constants as bc\n",
    "from qanta.util.multiprocess import _multiprocess\n",
    "from qanta import logging\n",
    "\n",
    "Batch = namedtuple('Batch', ['qids', 'answers', 'mask', 'vecs', 'results'])\n",
    "\n",
    "N_GUESSERS = len(GUESSERS)\n",
    "N_GUESSES = conf['buzzer']['n_guesses']\n",
    "\n",
    "log = logging.get(__name__)\n",
    "\n",
    "class QuestionIteratorNoPos(object):\n",
    "    '''Each batch contains:\n",
    "        qids: list, (batch_size,)\n",
    "        answers: list, (batch_size,)\n",
    "        mask: list, (length, batch_size,)\n",
    "        vecs: xp.float32, (length, batch_size, 4 * NUM_GUESSES)\n",
    "        results: xp.int32, (length, batch_size)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, dataset: list, option2id: Dict[str, int], batch_size:int,\n",
    "            bucket_size=4, step_size=1, neg_weight=1, shuffle=True, pkl_dir=None):\n",
    "        self.dataset = dataset\n",
    "        self.option2id = option2id\n",
    "        self.batch_size = batch_size\n",
    "        self.bucket_size = bucket_size\n",
    "        self.step_size = step_size\n",
    "        self.neg_weight = neg_weight\n",
    "        self.shuffle = shuffle\n",
    "        self.epoch = 0\n",
    "        self.iteration = 0\n",
    "        self.batch_index = 0\n",
    "        self.is_end_epoch = False\n",
    "        sys.stdout.flush()\n",
    "        if pkl_dir is not None:\n",
    "            if os.path.exists(pkl_dir):\n",
    "                with open(pkl_dir, 'rb') as f:\n",
    "                    self.batches = pickle.load(f)\n",
    "                log.info('Finish loading batches')\n",
    "            else:\n",
    "                log.info('Creating batches (nopos)')\n",
    "                self.create_batches()\n",
    "                with open(pkl_dir, 'wb') as f:\n",
    "                    pickle.dump(self.batches, f)\n",
    "                log.info('Finish creating batches')\n",
    "        else:\n",
    "            log.info('Creating batches (nopos)')\n",
    "            self.create_batches()\n",
    "            log.info('Finish creating batches')\n",
    "\n",
    "    def get_guesser_acc(self, i, length):\n",
    "        if i == length:\n",
    "            return bc.GUESSER_ACC[-1]\n",
    "        if i == 0:\n",
    "            return bc.GUESSER_ACC[0]\n",
    "        ratio = i / length\n",
    "        pos = 0\n",
    "        for i, r in enumerate(bc.GUESSER_ACC_POS):\n",
    "            if r > ratio:\n",
    "                pos = i\n",
    "                break\n",
    "        acc = bc.GUESSER_ACC[pos - 1] * (ratio - bc.GUESSER_ACC_POS[pos - 1]) +\\\n",
    "                bc.GUESSER_ACC[pos] * (bc.GUESSER_ACC_POS[pos] - ratio)\n",
    "        return acc\n",
    "\n",
    "    def dense_vector(self, dicts: List[List[Dict[str, float]]],\n",
    "            wordvecs: List[List[np.ndarray]], step_size=1) -> List[List[float]]:\n",
    "        '''Generate dense vectors from a sequence of guess dictionaries.\n",
    "        dicts: a sequence of guess dictionaries for each guesser\n",
    "        '''\n",
    "        length = len(dicts)\n",
    "        prev_vecs = [[0. for _ in range(N_GUESSERS * N_GUESSES)] \\\n",
    "                for i in range(step_size)]\n",
    "        vecs = []\n",
    "        for i in range(length):\n",
    "            if len(dicts[i]) != N_GUESSERS:\n",
    "                raise ValueError(\"Inconsistent number of guessers ({0}, {1}).\".format(\n",
    "                    N_GUESSERS, len(dicts)))\n",
    "            vec = []\n",
    "            diff_vec = []\n",
    "            isnew_vec = []\n",
    "            for j in range(N_GUESSERS):\n",
    "                dic = sorted(dicts[i][j].items(), key=lambda x: x[1], reverse=True)\n",
    "                for guess, score in dic:\n",
    "                    vec.append(score)\n",
    "                    if i > 0 and guess in dicts[i-1][j]:\n",
    "                        diff_vec.append(score - dicts[i-1][j][guess])\n",
    "                        isnew_vec.append(0)\n",
    "                    else:\n",
    "                        diff_vec.append(score) \n",
    "                        isnew_vec.append(1)\n",
    "                if len(dic) < N_GUESSES:\n",
    "                    for k in range(max(N_GUESSES - len(dic), 0)):\n",
    "                        vec.append(0)\n",
    "                        diff_vec.append(0)\n",
    "                        isnew_vec.append(0)\n",
    "            guesser_acc = self.get_guesser_acc(i, length)\n",
    "            features = [sum(isnew_vec), np.average(vec), vec[0], vec[1], vec[2],\n",
    "                    isnew_vec[0], isnew_vec[1], vec[0] - vec[1], vec[1] -\n",
    "                    vec[2], isnew_vec[2], diff_vec[0], \n",
    "                    vec[0] - prev_vecs[-1][0], np.var(vec),\n",
    "                    np.var(prev_vecs[-1])]\n",
    "\n",
    "            vecs.append(features)\n",
    "            prev_vecs.append(vec)\n",
    "            if step_size > 0:\n",
    "                prev_vecs = prev_vecs[-step_size:]\n",
    "        return vecs\n",
    "\n",
    "    def _process_example(self, qid, answer, dicts, results, wordvecs):\n",
    "        \n",
    "        results = np.asarray(results, dtype=np.int32)\n",
    "        length, n_guessers = results.shape\n",
    "\n",
    "        if n_guessers != N_GUESSERS:\n",
    "            raise ValueError(\n",
    "                \"Inconsistent number of guessers ({0}, {1}.\".format(\n",
    "                    N_GUESSERS, n_guessers))\n",
    "\n",
    "        # append the not buzzing action to each time step\n",
    "        # not buzzing = 1 when no guesser is correct\n",
    "        new_results = []\n",
    "        for i in range(length):\n",
    "            not_buzz = int(not any(results[i] == 1)) * self.neg_weight\n",
    "            new_results.append(np.append(results[i], not_buzz))\n",
    "        results = np.asarray(new_results, dtype=np.int32)\n",
    "\n",
    "        if len(dicts) != length:\n",
    "            raise ValueError(\"Inconsistant shape of results and vecs.\")\n",
    "        vecs = self.dense_vector(dicts, wordvecs, self.step_size)\n",
    "        vecs = np.asarray(vecs, dtype=np.float32)\n",
    "        assert length == vecs.shape[0]\n",
    "        self.n_input = len(vecs[0])\n",
    "\n",
    "        padded_length = -((-length) // self.bucket_size) * self.bucket_size\n",
    "        vecs_padded = np.zeros((padded_length, self.n_input))\n",
    "        vecs_padded[:length,:self.n_input] = vecs\n",
    "\n",
    "        results_padded = np.zeros((padded_length, (N_GUESSERS + 1)))\n",
    "        results_padded[:length, :(N_GUESSERS + 1)] = results\n",
    "\n",
    "        mask = [1 for _ in range(length)] + \\\n",
    "               [0 for _ in range(padded_length - length)]\n",
    "\n",
    "        example = (qid, answer, mask, vecs_padded, results_padded)\n",
    "        return example, padded_length\n",
    "\n",
    "    def create_batches(self):\n",
    "        self.batches = []\n",
    "        buckets = defaultdict(list)\n",
    "        total = len(self.dataset)\n",
    "        returns = _multiprocess(self._process_example, self.dataset,\n",
    "                info=\"creat batches\", multi=False)\n",
    "        for example, padded_length in returns:\n",
    "            buckets[padded_length].append(example)\n",
    "\n",
    "        for examples in buckets.values():\n",
    "            for i in range(0, len(examples), self.batch_size):\n",
    "                qids, answers, mask, vecs, results = \\\n",
    "                        zip(*examples[i : i + self.batch_size])\n",
    "                batch = Batch(qids, answers, mask, vecs, results)\n",
    "                self.batches.append(batch)\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return len(self.batches)\n",
    "    \n",
    "    def finalize(self, reset=False):\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.batches)\n",
    "        if reset:\n",
    "            self.epoch = 0\n",
    "            self.iteration = 0\n",
    "            self.batch_index = 0\n",
    "\n",
    "    def next_batch(self, xp, train=True):\n",
    "        self.iteration += 1\n",
    "        if self.batch_index == 0:\n",
    "            self.epoch += 1\n",
    "        self.is_end_epoch = (self.batch_index == self.size - 1)\n",
    "        qids, answers, mask, vecs, results = self.batches[self.batch_index]\n",
    "\n",
    "        vecs = xp.asarray(vecs, dtype=xp.float32).swapaxes(0, 1) # length * batch_size * dim\n",
    "        results = xp.asarray(results, dtype=xp.int32).swapaxes(0, 1) # length * batch_size * n_guessers\n",
    "        mask = xp.asarray(mask, dtype=xp.float32).T # length * batch_size\n",
    "        # results = results * 2 - 1 # convert from (0, 1) to (-1, 1)\n",
    "\n",
    "        self.batch_index = (self.batch_index + 1) % self.size\n",
    "        batch = Batch(qids, answers, mask, vecs, results)\n",
    "        return batch\n",
    "    \n",
    "    @property\n",
    "    def epoch_detail(self):\n",
    "        return self.iteration, self.iteration * 1.0 / self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-25 18:17:37,942 - __main__ - INFO - Creating batches (nopos)\n",
      "[creat batches] (1) done: 23210/23211\n",
      "2017-05-25 18:23:01,426 - __main__ - INFO - Finish creating batches\n",
      "2017-05-25 18:23:01,427 - __main__ - INFO - Creating batches (nopos)\n",
      "[creat batches] (1) done: 7586/7587\n",
      "2017-05-25 18:24:19,470 - __main__ - INFO - Finish creating batches\n",
      "2017-05-25 18:24:19,471 - __main__ - INFO - Creating batches (nopos)\n",
      "[creat batches] (1) done: 2088/2089\n",
      "2017-05-25 18:24:48,339 - __main__ - INFO - Finish creating batches\n",
      "2017-05-25 18:24:48,340 - __main__ - INFO - Creating batches (nopos)\n",
      "[creat batches] (1) done: 1411/1412\n",
      "2017-05-25 18:25:16,361 - __main__ - INFO - Finish creating batches\n",
      "2017-05-25 18:25:16,363 - __main__ - INFO - Creating batches (nopos)\n",
      "[creat batches] (1) done: 68/69\n",
      "2017-05-25 18:25:16,935 - __main__ - INFO - Finish creating batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "iterators = dict()\n",
    "for fold in c.BUZZER_INPUT_FOLDS:\n",
    "    iterators[fold] = QuestionIteratorNoPos(all_guesses[fold], option2id,\n",
    "        batch_size=128, step_size=1, neg_weight=1)\n",
    "print(iterators[c.BUZZER_TRAIN_FOLD].n_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import cuda\n",
    "\n",
    "class RNN(chainer.Chain):\n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        super(RNN, self).__init__(\n",
    "            rnn=L.LSTM(n_input, n_hidden),\n",
    "            linear=L.Linear(n_hidden, n_output))\n",
    "\n",
    "    @property\n",
    "    def xp(self):\n",
    "        if not cuda.available or self.linear._cpu:\n",
    "            return np\n",
    "        return cuda.cupy\n",
    "\n",
    "    def get_device(self):\n",
    "        if not cuda.available or self.linear._cpu:\n",
    "            return -1\n",
    "        return self.linear._device_id\n",
    "\n",
    "    def __call__(self, xs, train=True):\n",
    "        length, batch_size, _ = xs.shape\n",
    "        self.rnn.reset_state()\n",
    "        ys = F.stack([self.rnn(x) for x in xs], axis=0)\n",
    "        ys = F.reshape(ys, (length * batch_size, -1))\n",
    "        ys = self.linear(ys)\n",
    "        return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfg = configs.rnn()\n",
    "cfg.n_hidden = 25\n",
    "cfg.model_dir = 'output/buzzer/rnn_nopos_25.npz'\n",
    "model = RNN(iterators[c.BUZZER_TRAIN_FOLD].n_input, cfg.n_hidden, 2)\n",
    "\n",
    "chainer.cuda.get_device(0).use()\n",
    "model.to_gpu(0)\n",
    "\n",
    "pickle.dump(cfg, open(cfg.ckp_dir, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-25 18:57:42,700 - qanta.buzzer.trainer - INFO - epoch 0\n",
      "2017-05-25 18:58:21,535 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.66  \n",
      "2017-05-25 18:58:26,778 - qanta.buzzer.trainer - INFO - eval loss: 0.01  acc: 0.75  \n",
      "2017-05-25 18:58:26,783 - qanta.buzzer.trainer - INFO - epoch 1\n",
      "2017-05-25 18:58:55,687 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.76  \n",
      "2017-05-25 18:59:04,825 - qanta.buzzer.trainer - INFO - eval loss: 0.01  acc: 0.80  \n",
      "2017-05-25 18:59:04,833 - qanta.buzzer.trainer - INFO - epoch 2\n",
      "2017-05-25 18:59:33,868 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.80  \n",
      "2017-05-25 18:59:41,485 - qanta.buzzer.trainer - INFO - eval loss: 0.01  acc: 0.80  \n",
      "2017-05-25 18:59:41,491 - qanta.buzzer.trainer - INFO - epoch 3\n",
      "2017-05-25 19:00:14,217 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.81  \n",
      "2017-05-25 19:00:20,910 - qanta.buzzer.trainer - INFO - eval loss: 0.01  acc: 0.80  \n",
      "2017-05-25 19:00:20,916 - qanta.buzzer.trainer - INFO - epoch 4\n",
      "2017-05-25 19:00:52,239 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.82  \n",
      "2017-05-25 19:00:57,479 - qanta.buzzer.trainer - INFO - eval loss: 0.01  acc: 0.80  \n",
      "2017-05-25 19:00:57,485 - qanta.buzzer.trainer - INFO - epoch 5\n",
      "2017-05-25 19:01:36,711 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.82  \n",
      "2017-05-25 19:01:41,978 - qanta.buzzer.trainer - INFO - eval loss: 0.01  acc: 0.81  \n",
      "2017-05-25 19:01:41,984 - qanta.buzzer.trainer - INFO - epoch 6\n",
      "2017-05-25 19:02:28,254 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.83  \n",
      "2017-05-25 19:02:39,323 - qanta.buzzer.trainer - INFO - eval loss: 0.01  acc: 0.83  \n",
      "2017-05-25 19:02:39,330 - qanta.buzzer.trainer - INFO - epoch 7\n",
      "2017-05-25 19:03:12,321 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.83  \n",
      "2017-05-25 19:03:17,632 - qanta.buzzer.trainer - INFO - eval loss: 0.01  acc: 0.83  \n",
      "2017-05-25 19:03:17,637 - qanta.buzzer.trainer - INFO - epoch 8\n",
      "2017-05-25 19:03:46,348 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.84  \n",
      "2017-05-25 19:03:51,609 - qanta.buzzer.trainer - INFO - eval loss: 0.00  acc: 0.84  \n",
      "2017-05-25 19:03:51,614 - qanta.buzzer.trainer - INFO - epoch 9\n",
      "2017-05-25 19:04:29,290 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.84  \n",
      "2017-05-25 19:04:37,980 - qanta.buzzer.trainer - INFO - eval loss: 0.00  acc: 0.84  \n",
      "2017-05-25 19:04:37,986 - qanta.buzzer.trainer - INFO - epoch 10\n",
      "2017-05-25 19:05:11,474 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.84  \n",
      "2017-05-25 19:05:18,151 - qanta.buzzer.trainer - INFO - eval loss: 0.01  acc: 0.84  \n",
      "2017-05-25 19:05:18,158 - qanta.buzzer.trainer - INFO - epoch 11\n",
      "2017-05-25 19:05:55,096 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.84  \n",
      "2017-05-25 19:06:00,508 - qanta.buzzer.trainer - INFO - eval loss: 0.00  acc: 0.82  \n",
      "2017-05-25 19:06:00,513 - qanta.buzzer.trainer - INFO - epoch 12\n",
      "2017-05-25 19:06:30,631 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.84  \n",
      "2017-05-25 19:06:36,070 - qanta.buzzer.trainer - INFO - eval loss: 0.00  acc: 0.84  \n",
      "2017-05-25 19:06:36,075 - qanta.buzzer.trainer - INFO - epoch 13\n",
      "2017-05-25 19:07:03,131 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.84  \n",
      "2017-05-25 19:07:11,239 - qanta.buzzer.trainer - INFO - eval loss: 0.01  acc: 0.83  \n",
      "2017-05-25 19:07:11,244 - qanta.buzzer.trainer - INFO - epoch 14\n",
      "2017-05-25 19:07:46,906 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.84  \n",
      "2017-05-25 19:07:53,843 - qanta.buzzer.trainer - INFO - eval loss: 0.01  acc: 0.83  \n",
      "2017-05-25 19:07:53,848 - qanta.buzzer.trainer - INFO - epoch 15\n",
      "2017-05-25 19:08:18,724 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.84  \n",
      "2017-05-25 19:08:24,093 - qanta.buzzer.trainer - INFO - eval loss: 0.00  acc: 0.84  \n",
      "2017-05-25 19:08:24,098 - qanta.buzzer.trainer - INFO - epoch 16\n",
      "2017-05-25 19:08:55,604 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.84  \n",
      "2017-05-25 19:09:00,997 - qanta.buzzer.trainer - INFO - eval loss: 0.00  acc: 0.84  \n",
      "2017-05-25 19:09:01,003 - qanta.buzzer.trainer - INFO - epoch 17\n",
      "2017-05-25 19:09:25,979 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.85  \n",
      "2017-05-25 19:09:31,315 - qanta.buzzer.trainer - INFO - eval loss: 0.00  acc: 0.84  \n",
      "2017-05-25 19:09:31,321 - qanta.buzzer.trainer - INFO - epoch 18\n",
      "2017-05-25 19:09:57,791 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.85  \n",
      "2017-05-25 19:10:06,950 - qanta.buzzer.trainer - INFO - eval loss: 0.00  acc: 0.85  \n",
      "2017-05-25 19:10:06,961 - qanta.buzzer.trainer - INFO - epoch 19\n",
      "2017-05-25 19:10:42,746 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.85  \n",
      "2017-05-25 19:10:51,682 - qanta.buzzer.trainer - INFO - eval loss: 0.00  acc: 0.84  \n",
      "2017-05-25 19:10:51,688 - qanta.buzzer.trainer - INFO - epoch 20\n",
      "2017-05-25 19:11:23,858 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.85  \n",
      "2017-05-25 19:11:29,164 - qanta.buzzer.trainer - INFO - eval loss: 0.00  acc: 0.84  \n",
      "2017-05-25 19:11:29,169 - qanta.buzzer.trainer - INFO - epoch 21\n",
      "2017-05-25 19:12:03,962 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.85  \n",
      "2017-05-25 19:12:09,243 - qanta.buzzer.trainer - INFO - eval loss: 0.00  acc: 0.84  \n",
      "2017-05-25 19:12:09,247 - qanta.buzzer.trainer - INFO - epoch 22\n",
      "2017-05-25 19:12:36,876 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.85  \n",
      "2017-05-25 19:12:43,693 - qanta.buzzer.trainer - INFO - eval loss: 0.03  acc: 0.85  \n",
      "2017-05-25 19:12:43,698 - qanta.buzzer.trainer - INFO - epoch 23\n",
      "2017-05-25 19:13:11,322 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.85  \n",
      "2017-05-25 19:13:22,038 - qanta.buzzer.trainer - INFO - eval loss: 0.00  acc: 0.84  \n",
      "2017-05-25 19:13:22,278 - qanta.buzzer.trainer - INFO - epoch 24\n",
      "2017-05-25 19:13:52,339 - qanta.buzzer.trainer - INFO - train loss: 0.00  acc: 0.85  \n",
      "2017-05-25 19:13:57,603 - qanta.buzzer.trainer - INFO - eval loss: 0.00  acc: 0.84  \n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model,'output/buzzer/rnn_nopos_25.npz')\n",
    "trainer.run(iterators[c.BUZZER_TRAIN_FOLD], iterators[c.BUZZER_DEV_FOLD], 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-25 19:14:02,950 - __main__ - INFO - Buzzes generated. Size 7587.\n",
      "2017-05-25 19:14:03,094 - __main__ - INFO - Buzzes saved to output/buzzer/buzzerdev_buzzes_rnn_nopos_25.pkl.\n",
      "2017-05-25 19:14:07,764 - __main__ - INFO - Buzzes generated. Size 2089.\n",
      "2017-05-25 19:14:07,818 - __main__ - INFO - Buzzes saved to output/buzzer/dev_buzzes_rnn_nopos_25.pkl.\n",
      "2017-05-25 19:14:11,901 - __main__ - INFO - Buzzes generated. Size 1412.\n",
      "2017-05-25 19:14:11,931 - __main__ - INFO - Buzzes saved to output/buzzer/test_buzzes_rnn_nopos_25.pkl.\n",
      "2017-05-25 19:14:12,174 - __main__ - INFO - Buzzes generated. Size 69.\n",
      "2017-05-25 19:14:12,176 - __main__ - INFO - Buzzes saved to output/buzzer/expo_buzzes_rnn_nopos_25.pkl.\n"
     ]
    }
   ],
   "source": [
    "BUZZES_DIR='output/buzzer/{0}_buzzes_{1}.pkl'\n",
    "for fold in c.BUZZER_GENERATION_FOLDS:\n",
    "    buzzes = trainer.test(iterators[fold])\n",
    "    log.info('Buzzes generated. Size {0}.'.format(len(buzzes)))\n",
    "    buzzes_dir = BUZZES_DIR.format(fold, 'rnn_nopos_25')\n",
    "    with open(buzzes_dir, 'wb') as outfile:\n",
    "        pickle.dump(buzzes, outfile)\n",
    "    log.info('Buzzes saved to {0}.'.format(buzzes_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(iterators[c.BUZZER_TRAIN_FOLD].n_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
