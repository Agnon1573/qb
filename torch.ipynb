{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from qanta.guesser.torch.dan import *\n",
    "from qanta.datasets.quiz_bowl import QuizBowlDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = QuizBowlDataset(1, guesser_train=True)\n",
    "training_data = dataset.training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_text, y_train, x_test_text, y_test, vocab, class_to_i, i_to_class = preprocess_dataset(\n",
    "    training_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, embedding_lookup = load_embeddings(vocab=vocab, expand_glove=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.array([convert_text_to_embeddings_indices(q, embedding_lookup) for q in x_train_text])\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_test = np.array([convert_text_to_embeddings_indices(q, embedding_lookup) for q in x_test_text])\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = compute_n_classes(training_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_to_word = {ind: word for word, ind in embedding_lookup.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(' '.join([i_to_word[ind] for ind in x_train[i]]))\n",
    "    print(i_to_class[y_train[i]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = x_train.shape[0]\n",
    "batch_size = 512\n",
    "n_batches = n_examples // batch_size\n",
    "random_order = np.random.permutation(n_examples)\n",
    "x_train = x_train[random_order]\n",
    "y_train = y_train[random_order]\n",
    "\n",
    "t_x_batches = []\n",
    "t_offset_batches = []\n",
    "t_y_batches = []\n",
    "\n",
    "for b in range(n_batches):\n",
    "    x_batch = x_train[b * batch_size:(b + 1) * batch_size]\n",
    "    y_batch = y_train[b * batch_size:(b + 1) * batch_size]\n",
    "    \n",
    "    flat_x_batch = []\n",
    "    for r in x_batch:\n",
    "        flat_x_batch.extend(r)\n",
    "    flat_x_batch = np.array(flat_x_batch)\n",
    "    x_lengths = [len(r) for r in x_batch]\n",
    "    offsets = np.cumsum([0] + x_lengths[:-1])\n",
    "    \n",
    "    t_x_batches.append(torch.from_numpy(flat_x_batch).long().cuda())\n",
    "    t_offset_batches.append(torch.from_numpy(offsets).long().cuda())\n",
    "    t_y_batches.append(torch.from_numpy(y_batch).long().cuda())\n",
    "\n",
    "t_x_batches = np.array(t_x_batches)\n",
    "t_offset_batches = np.array(t_offset_batches)\n",
    "t_y_batches = np.array(t_y_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = DanModel(embeddings.shape[0], n_classes)\n",
    "model.init_weights(initial_embeddings=embeddings)\n",
    "model.train()\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_gradient = float('-inf')\n",
    "min_gradient = float('inf')\n",
    "accuracies = []\n",
    "losses = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    random_batch_order = np.random.permutation(n_batches)\n",
    "    t_x_batches = t_x_batches[random_batch_order]\n",
    "    t_offset_batches = t_offset_batches[random_batch_order]\n",
    "    t_y_batches = t_y_batches[random_batch_order]\n",
    "\n",
    "    batch_accuracies = []\n",
    "    batch_losses = []\n",
    "    epoch_start = time.time()\n",
    "    print('Starting epoch: ', epoch)\n",
    "    for batch in range(n_batches):\n",
    "        t_x_batch = Variable(t_x_batches[batch])#.cuda())\n",
    "        t_offsets = Variable(t_offset_batches[batch])#.cuda())\n",
    "        t_y_batch = Variable(t_y_batches[batch])#.cuda())\n",
    "\n",
    "        model.zero_grad()\n",
    "        out = model(t_x_batch, t_offsets)\n",
    "        _, preds = torch.max(out, 1)\n",
    "\n",
    "        accuracy = torch.mean(torch.eq(preds, t_y_batch).float()).data[0]\n",
    "        batch_loss = criterion(out, t_y_batch)\n",
    "\n",
    "        batch_accuracies.append(accuracy)\n",
    "        batch_losses.append(batch_loss.data[0])\n",
    "\n",
    "        batch_loss.backward()\n",
    "        #for p in model.parameters():\n",
    "        #    max_gradient = max(max_gradient, p.grad.max().data[0])\n",
    "        #    min_gradient = min(min_gradient, p.grad.min().data[0])\n",
    "            \n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_accuracy = np.mean(batch_accuracies)\n",
    "    epoch_loss = np.mean(batch_losses)\n",
    "    \n",
    "    accuracies.append(epoch_accuracy)\n",
    "    losses.append(epoch_loss)\n",
    "            \n",
    "    epoch_end = time.time()\n",
    "    print('Epoch: time={} accuracy={} loss={}'.format(epoch_end - epoch_start, epoch_accuracy, epoch_loss))\n",
    "    #print(max_gradient, min_gradient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
