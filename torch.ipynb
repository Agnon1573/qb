{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from qanta.guesser.torch.dan import *\n",
    "from qanta.datasets.quiz_bowl import QuizBowlDataset\n",
    "import abc\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = QuizBowlDataset(1, guesser_train=True)\n",
    "training_data = dataset.training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_text, y_train, x_test_text, y_test, vocab, class_to_i, i_to_class = preprocess_dataset(\n",
    "    training_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-18 13:50:28,264 - qanta.guesser.torch.dan - INFO - Loading word embeddings from tmp cache\n"
     ]
    }
   ],
   "source": [
    "embeddings, embedding_lookup = load_embeddings(vocab=vocab, expand_glove=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.array([convert_text_to_embeddings_indices(q, embedding_lookup) for q in x_train_text])\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_test = np.array([convert_text_to_embeddings_indices(q, embedding_lookup) for q in x_test_text])\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = compute_n_classes(training_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_to_word = {ind: word for word, ind in embedding_lookup.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_and_offset(x_batch):\n",
    "    flat_x_batch = []\n",
    "    for r in x_batch:\n",
    "        flat_x_batch.extend(r)\n",
    "    flat_x_batch = np.array(flat_x_batch)\n",
    "    x_lengths = [len(r) for r in x_batch]\n",
    "    offsets = np.cumsum([0] + x_lengths[:-1])\n",
    "    return flat_x_batch, offsets\n",
    "\n",
    "def batchify(batch_size, x_array, y_array, truncate=True):\n",
    "    n_examples = x_array.shape[0]\n",
    "    n_batches = n_examples // batch_size\n",
    "    random_order = np.random.permutation(n_examples)\n",
    "    x_array = x_array[random_order]\n",
    "    y_array = y_array[random_order]\n",
    "\n",
    "    t_x_batches = []\n",
    "    t_offset_batches = []\n",
    "    t_y_batches = []\n",
    "\n",
    "    for b in range(n_batches):\n",
    "        x_batch = x_array[b * batch_size:(b + 1) * batch_size]\n",
    "        y_batch = y_array[b * batch_size:(b + 1) * batch_size]\n",
    "        flat_x_batch, offsets = flatten_and_offset(x_batch)\n",
    "\n",
    "        t_x_batches.append(torch.from_numpy(flat_x_batch).long().cuda())\n",
    "        t_offset_batches.append(torch.from_numpy(offsets).long().cuda())\n",
    "        t_y_batches.append(torch.from_numpy(y_batch).long().cuda())\n",
    "    \n",
    "    if (not truncate) and (batch_size * n_batches < n_examples):\n",
    "        x_batch = x_array[n_batches * batch_size:]\n",
    "        y_batch = y_array[n_batches * batch_size:]\n",
    "        flat_x_batch, offsets = flatten_and_offset(x_batch)\n",
    "        \n",
    "        t_x_batches.append(torch.from_numpy(flat_x_batch).long().cuda())\n",
    "        t_offset_batches.append(torch.from_numpy(offsets).long().cuda())\n",
    "        t_y_batches.append(torch.from_numpy(y_batch).long().cuda())\n",
    "\n",
    "    t_x_batches = np.array(t_x_batches)\n",
    "    t_offset_batches = np.array(t_offset_batches)\n",
    "    t_y_batches = np.array(t_y_batches)\n",
    "    \n",
    "    return n_batches, t_x_batches, t_offset_batches, t_y_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "n_batches_train, t_x_train, t_offset_train, t_y_train = batchify(batch_size, x_train, y_train, truncate=True)\n",
    "n_batches_test, t_x_test, t_offset_test, t_y_test = batchify(batch_size, x_test, y_test, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(model, n_batches, t_x_array, t_offset_array, t_y_array, evaluate=False):\n",
    "    if not evaluate:\n",
    "        random_batch_order = np.random.permutation(n_batches)\n",
    "        t_x_array = t_x_array[random_batch_order]\n",
    "        t_offset_array = t_offset_array[random_batch_order]\n",
    "        t_y_array = t_y_array[random_batch_order]\n",
    "    \n",
    "    batch_accuracies = []\n",
    "    batch_losses = []\n",
    "    epoch_start = time.time()\n",
    "    for batch in range(n_batches):\n",
    "        t_x_batch = Variable(t_x_array[batch], volatile=evaluate)\n",
    "        t_offset_batch = Variable(t_offset_array[batch], volatile=evaluate)\n",
    "        t_y_batch = Variable(t_y_array[batch], volatile=evaluate)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        out = model(t_x_batch, t_offset_batch)\n",
    "        _, preds = torch.max(out, 1)\n",
    "        accuracy = torch.mean(torch.eq(preds, t_y_batch).float()).data[0]\n",
    "        batch_loss = criterion(out, t_y_batch)\n",
    "        if not evaluate:\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        batch_accuracies.append(accuracy)\n",
    "        batch_losses.append(batch_loss.data[0])\n",
    "    \n",
    "    epoch_end = time.time()\n",
    "        \n",
    "    return np.mean(batch_accuracies), np.mean(batch_losses), epoch_end - epoch_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = DanModel(embeddings.shape[0], n_classes)\n",
    "model.init_weights(initial_embeddings=embeddings)\n",
    "model.train()\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Callback(abc.ABCMeta):\n",
    "    @abc.abstractmethod()\n",
    "    def on_epoch_end(logs):\n",
    "        pass\n",
    "\n",
    "class BaseLogger(Callback):\n",
    "    def on_epoch_end(self, logs):\n",
    "        print('Epoch {}: train_acc={} test_acc={} | train_loss={} test_loss={} | time={}'.format(\n",
    "            len(logs['train_acc']),\n",
    "            logs['train_acc'][-1], logs['test_acc'][-1],\n",
    "            logs['train_loss'][-1], logs['test_loss'][-1],\n",
    "            logs['train_time'][-1]\n",
    "        ))\n",
    "        return False, []\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'BaseLogger()'\n",
    "\n",
    "class TerminateOnNaN(Callback):\n",
    "    def on_epoch_end(self, logs):\n",
    "        for key, arr in logs.items():\n",
    "            if np.any(np.isnan(arr)):\n",
    "                return True, 'NaN encountered in {} containing {}'.format(key, arr)\n",
    "        else:\n",
    "            return False, None\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'TerminateOnNaN()'\n",
    "\n",
    "class EarlyStopping(Callback):\n",
    "    def __init__(self, monitor='test_loss', min_delta=0, patience=0):\n",
    "        if monitor.endswith('loss'):\n",
    "            self.improvement_sign = 1\n",
    "        elif monitor.endswith('accuracy'):\n",
    "            self.improvement_sign = -1\n",
    "        else:\n",
    "            raise ValueError('Unrecognized monitor')\n",
    "        self.monitor = monitor\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.best_monitor_score = self.improvement_sign * float('inf')\n",
    "        self.current_patience = patience\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'EarlyStopping(monitor={}, min_delta={}, patience={})'.format(\n",
    "            self.monitor, self.min_delta, self.patience)\n",
    "        \n",
    "    def on_epoch_end(self, logs):\n",
    "        if self.logs[self.monitor][-1] * self.improvement_sign < self.improvement_sign * self.best_monitor_score:\n",
    "            self.current_patience = self.patience\n",
    "            self.best_monitor_score = self.logs[self.monitor][-1]\n",
    "        else:\n",
    "            self.current_patience -= 1\n",
    "        \n",
    "        if self.current_patience == 0:\n",
    "            return True, 'Ran out of patience'\n",
    "        else:\n",
    "            return False, None\n",
    "\n",
    "\n",
    "class ModelCheckpoint(Callback):\n",
    "    def __init__(model, filepath, monitor='test_loss', save_best_only=True, overwrite=True):\n",
    "        self.model = model\n",
    "        self.filepath = filepath\n",
    "        self.save_best_only = save_best_only\n",
    "        self.overwrite = overwrite\n",
    "        if monitor.endswith('loss'):\n",
    "            self.improvement_sign = 1\n",
    "        elif monitor.endswith('accuracy'):\n",
    "            self.improvement_sign = -1\n",
    "        else:\n",
    "            raise ValueError('Unrecognized monitor')\n",
    "        self.monitor = monitor\n",
    "        self.best_monitor_score = self.improvement_sign * float('inf')\n",
    "    \n",
    "    def on_epoch_end(self, logs):\n",
    "        if self.logs[self.monitor][-1] * self.improvement_sign < self.improvement_sign * self.best_monitor_score:\n",
    "            self.current_patience = self.patience\n",
    "            self.best_monitor_score = self.logs[self.monitor][-1]\n",
    "        else:\n",
    "            self.current_patience -= 1\n",
    "\n",
    "\n",
    "class TrainingManager:\n",
    "    def __init__(self, callbacks, default_callbacks=[]):\n",
    "        self.callbacks = callbacks\n",
    "        \n",
    "        for c in default_callbacks:\n",
    "            pass\n",
    "        \n",
    "        self.logs = defaultdict(list)\n",
    "    \n",
    "    def instruct(self, train_time, train_loss, train_acc, test_time, test_loss, test_acc):\n",
    "        self.logs['train_time'].append(train_time)\n",
    "        self.logs['train_loss'].append(train_loss)\n",
    "        self.logs['train_acc'].append(train_acc)\n",
    "        self.logs['test_time'].append(test_time)\n",
    "        self.logs['test_loss'].append(test_loss)\n",
    "        self.logs['test_acc'].append(test_acc)\n",
    "        \n",
    "        callback_stop_reasons = []\n",
    "        for c in self.callbacks:\n",
    "            stop_training, reason = c.on_epoch_end(self.logs)\n",
    "            if stop_training:\n",
    "                callback_stop_reasons.append(reason)\n",
    "        \n",
    "        if len(callback_stop_reasons) > 0:\n",
    "            return True, callback_stop_reasons\n",
    "        else:\n",
    "            return False, []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: time=12.4 train_accuracy=0.0000 train_loss=0.0000test_accuracy=0.0026 test_loss=8.7164\n",
      "Epoch 1: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-3bab484396e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     train_epoch_accuracy, train_epoch_loss, train_epoch_time = run_epoch(\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batches_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mt_x_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_offset_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m     \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_epoch_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-6a7efc705d4c>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(model, n_batches, t_x_array, t_offset_array, t_y_array, evaluate)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_x_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_offset_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/qb/qanta/guesser/torch/dan.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_, offsets)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mavg_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, offsets)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         )(self.weight, input, offsets)\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/nn/_functions/thnn/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, weight, indices, offsets)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"offsets has to be a 1D Tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             raise ValueError(\"offsets[0] has to be 0, i.e. the first sequence\"\n\u001b[1;32m    153\u001b[0m                              \u001b[0;34m\" in the mini-batch has to start from position 0.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "manager = TrainingManager([])\n",
    "\n",
    "for epoch in range(100):\n",
    "    print(f'Epoch {epoch}: ', end='')\n",
    "    train_accuracy, train_loss, train_time = run_epoch(\n",
    "        model, n_batches_train,\n",
    "        t_x_train, t_offset_train, t_y_train, evaluate=False\n",
    "    )\n",
    "   \n",
    "    test_accuracy, test_loss, test_time = run_epoch(\n",
    "        model, n_batches_test,\n",
    "        t_x_test, t_offset_test, t_y_test, evaluate=True\n",
    "    )\n",
    "    \n",
    "    stop_training, reasons = manager.instruct(\n",
    "        train_time, train_loss, train_acc,\n",
    "        test_time, test_loss, test_acc\n",
    "    )\n",
    "    \n",
    "    if stop_training:\n",
    "        print(reason)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
