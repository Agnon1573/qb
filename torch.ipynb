{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from qanta.guesser.torch.dan import *\n",
    "from qanta.datasets.quiz_bowl import QuizBowlDataset\n",
    "from qanta.manager import BaseLogger, TerminateOnNaN, EarlyStopping, ModelCheckpoint, MaxEpochStopping, TrainingManager\n",
    "import abc\n",
    "from collections import defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = QuizBowlDataset(1, guesser_train=True)\n",
    "training_data = dataset.training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_text, y_train, x_test_text, y_test, vocab, class_to_i, i_to_class = preprocess_dataset(\n",
    "    training_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, embedding_lookup = load_embeddings(vocab=vocab, expand_glove=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.array([convert_text_to_embeddings_indices(q, embedding_lookup) for q in x_train_text])\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_test = np.array([convert_text_to_embeddings_indices(q, embedding_lookup) for q in x_test_text])\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = compute_n_classes(training_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_to_word = {ind: word for word, ind in embedding_lookup.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_and_offset(x_batch):\n",
    "    flat_x_batch = []\n",
    "    for r in x_batch:\n",
    "        flat_x_batch.extend(r)\n",
    "    flat_x_batch = np.array(flat_x_batch)\n",
    "    x_lengths = [len(r) for r in x_batch]\n",
    "    offsets = np.cumsum([0] + x_lengths[:-1])\n",
    "    return flat_x_batch, offsets\n",
    "\n",
    "def batchify(batch_size, x_array, y_array, truncate=True):\n",
    "    n_examples = x_array.shape[0]\n",
    "    n_batches = n_examples // batch_size\n",
    "    random_order = np.random.permutation(n_examples)\n",
    "    x_array = x_array[random_order]\n",
    "    y_array = y_array[random_order]\n",
    "\n",
    "    t_x_batches = []\n",
    "    t_offset_batches = []\n",
    "    t_y_batches = []\n",
    "\n",
    "    for b in range(n_batches):\n",
    "        x_batch = x_array[b * batch_size:(b + 1) * batch_size]\n",
    "        y_batch = y_array[b * batch_size:(b + 1) * batch_size]\n",
    "        flat_x_batch, offsets = flatten_and_offset(x_batch)\n",
    "\n",
    "        t_x_batches.append(torch.from_numpy(flat_x_batch).long().cuda())\n",
    "        t_offset_batches.append(torch.from_numpy(offsets).long().cuda())\n",
    "        t_y_batches.append(torch.from_numpy(y_batch).long().cuda())\n",
    "    \n",
    "    if (not truncate) and (batch_size * n_batches < n_examples):\n",
    "        x_batch = x_array[n_batches * batch_size:]\n",
    "        y_batch = y_array[n_batches * batch_size:]\n",
    "        flat_x_batch, offsets = flatten_and_offset(x_batch)\n",
    "        \n",
    "        t_x_batches.append(torch.from_numpy(flat_x_batch).long().cuda())\n",
    "        t_offset_batches.append(torch.from_numpy(offsets).long().cuda())\n",
    "        t_y_batches.append(torch.from_numpy(y_batch).long().cuda())\n",
    "\n",
    "    t_x_batches = np.array(t_x_batches)\n",
    "    t_offset_batches = np.array(t_offset_batches)\n",
    "    t_y_batches = np.array(t_y_batches)\n",
    "    \n",
    "    return n_batches, t_x_batches, t_offset_batches, t_y_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "n_batches_train, t_x_train, t_offset_train, t_y_train = batchify(batch_size, x_train, y_train, truncate=True)\n",
    "n_batches_test, t_x_test, t_offset_test, t_y_test = batchify(batch_size, x_test, y_test, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_x = Variable(t_x_test[0], volatile=True)\n",
    "t_offset = Variable(t_offset_test[0], volatile=True)\n",
    "t_y = Variable(t_y_test[0], volatile=True)\n",
    "\n",
    "model.eval()\n",
    "out = model(t_x, t_offset)\n",
    "probs = torch.nn.functional.softmax(out)\n",
    "scores, preds = torch.max(probs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(model, n_batches, t_x_array, t_offset_array, t_y_array, evaluate=False):\n",
    "    if not evaluate:\n",
    "        random_batch_order = np.random.permutation(n_batches)\n",
    "        t_x_array = t_x_array[random_batch_order]\n",
    "        t_offset_array = t_offset_array[random_batch_order]\n",
    "        t_y_array = t_y_array[random_batch_order]\n",
    "    \n",
    "    batch_accuracies = []\n",
    "    batch_losses = []\n",
    "    epoch_start = time.time()\n",
    "    for batch in range(n_batches):\n",
    "        t_x_batch = Variable(t_x_array[batch], volatile=evaluate)\n",
    "        t_offset_batch = Variable(t_offset_array[batch], volatile=evaluate)\n",
    "        t_y_batch = Variable(t_y_array[batch], volatile=evaluate)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        out = model(t_x_batch, t_offset_batch)\n",
    "        _, preds = torch.max(out, 1)\n",
    "        accuracy = torch.mean(torch.eq(preds, t_y_batch).float()).data[0]\n",
    "        batch_loss = criterion(out, t_y_batch)\n",
    "        if not evaluate:\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        batch_accuracies.append(accuracy)\n",
    "        batch_losses.append(batch_loss.data[0])\n",
    "    \n",
    "    epoch_end = time.time()\n",
    "        \n",
    "    return np.mean(batch_accuracies), np.mean(batch_losses), epoch_end - epoch_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = DanModel(embeddings.shape[0], n_classes)\n",
    "model.init_weights(initial_embeddings=embeddings)\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_save_model(model):\n",
    "    def save_model(path):\n",
    "        torch.save(model, path)\n",
    "    return save_model\n",
    "\n",
    "manager = TrainingManager([\n",
    "    BaseLogger(), TerminateOnNaN(),\n",
    "    EarlyStopping(patience=5), ModelCheckpoint(create_save_model(model), '/tmp/dan.pt')\n",
    "])\n",
    "\n",
    "for epoch in range(100):\n",
    "    print('Starting epoch... ', end='')\n",
    "    model.train()\n",
    "    train_acc, train_loss, train_time = run_epoch(\n",
    "        model, n_batches_train,\n",
    "        t_x_train, t_offset_train, t_y_train, evaluate=False\n",
    "    )\n",
    "    \n",
    "    model.eval()\n",
    "    test_acc, test_loss, test_time = run_epoch(\n",
    "        model, n_batches_test,\n",
    "        t_x_test, t_offset_test, t_y_test, evaluate=True\n",
    "    )\n",
    "    \n",
    "    stop_training, reasons = manager.instruct(\n",
    "        train_time, train_loss, train_acc,\n",
    "        test_time, test_loss, test_acc\n",
    "    )\n",
    "    \n",
    "    if stop_training:\n",
    "        print(reasons)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
